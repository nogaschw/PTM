{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "sys.path.append('../..')\n",
    "from Model.helper import *\n",
    "from Config import Config\n",
    "from sklearn.metrics import roc_curve\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../Data'))\n",
    "from Data import *\n",
    "from choosedataset import *\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 False\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "data = [Codeworkout, Falcon][config.dataset]()\n",
    "df = data.df\n",
    "padding_size_code = 765\n",
    "loss_func = False\n",
    "df['num_snapshots'] = df['prev_tasks'].apply(lambda x: [len(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_future_q = set()\n",
    "for i in df['new_task_id']:\n",
    "    all_future_q.add(i)\n",
    "\n",
    "all_prev_q = set()\n",
    "for i in df['prev_tasks_id']:\n",
    "    all_prev_q = all_prev_q.union(set(i))\n",
    "all_problems = all_future_q.union(all_prev_q)\n",
    "vocab = {name: idx for idx, name in enumerate(all_problems)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1 - With last attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentDataset(Dataset):\n",
    "    def __init__(self, df, text_tokenizer, max_len_code=768, padding_size_code=100, padding_size_q=30):\n",
    "        self.df = df\n",
    "        self.vocab = text_tokenizer\n",
    "        self.vocab['empty'] = len(text_tokenizer)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {\n",
    "            'prev_problems_id': torch.tensor([self.vocab.get(pid) for pid in row[\"prev_tasks_id\"]]),\n",
    "            'prev_labels': torch.tensor(row['prev_labels']),\n",
    "            'future_problem_id': torch.tensor(self.vocab.get(row['new_task_id'])),\n",
    "            'label': torch.tensor(row['Label'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKTWithFutureTaskID(nn.Module):\n",
    "    def __init__(self, num_tasks, embed_size=3, lstm_hidden_size=512):\n",
    "        super(DKTWithFutureTaskID, self).__init__()\n",
    "        self.task_embedding = nn.Embedding(num_tasks, embed_size)        # Embedding layer for the task IDs\n",
    "        self.lstm = nn.LSTM(input_size=embed_size + 1, hidden_size=lstm_hidden_size, num_layers=1, batch_first=True)  # Task embedding + binary success/failure\n",
    "        self.fc = nn.Linear((lstm_hidden_size + embed_size), 1)\n",
    "        self.fc_all = nn.Linear(lstm_hidden_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, past_task_ids, past_successes, future_task_id):\n",
    "        past_task_embeddings = self.task_embedding(past_task_ids)  # Shape: (batch_size, num_past_tasks, embed_size)\n",
    "        past_input = torch.cat([past_task_embeddings, past_successes.unsqueeze(-1).float()], dim=-1)          \n",
    "        lstm_out, _ = self.lstm(past_input)  \n",
    "        final_lstm_out = lstm_out[:, -1, :] # Take the final LSTM output (from the last time step)        \n",
    "        future_task_embeddings = self.task_embedding(future_task_id) # Embed the future task ID \n",
    "        combined_input = torch.cat([final_lstm_out, future_task_embeddings], dim=-1) # Combine the LSTM output with the future task embedding\n",
    "        output = self.fc(combined_input)\n",
    "        all_question_preds = self.sig(self.fc_all(lstm_out))\n",
    "        return all_question_preds, self.sig(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2 - With all attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentDataset(Dataset):\n",
    "    def __init__(self, df, text_tokenizer, max_len_code=768, padding_size_code=100, padding_size_q=30):\n",
    "        self.df = df\n",
    "        self.padding = padding_size_code\n",
    "        self.vocab = text_tokenizer\n",
    "        self.vocab['empty'] = len(text_tokenizer)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        prev_problem_id = torch.zeros((self.padding), dtype=torch.long)\n",
    "        prev_label = torch.zeros((self.padding), dtype=torch.long)\n",
    "        c = 0\n",
    "        for i, s in enumerate(row['num_snapshots']):\n",
    "            prev_problem_id_i = self.vocab.get(row[\"prev_tasks_id\"][i])\n",
    "            for j in range(s):\n",
    "                prev_problem_id[c] = prev_problem_id_i\n",
    "                prev_label[c] = row[\"prev_labels\"][i] if s - 1 == j else False\n",
    "                c += 1\n",
    "        return {\n",
    "            'code_num': torch.tensor(sum(row['num_snapshots'])), \n",
    "            'prev_problems_id': prev_problem_id,\n",
    "            'prev_labels': prev_label,\n",
    "            'future_problem_id': torch.tensor(self.vocab.get(row['new_task_id'])),\n",
    "            'label': torch.tensor(row['Label'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKTWithFutureTaskID(nn.Module):\n",
    "    def __init__(self, num_tasks, embed_size=3, lstm_hidden_size=64):\n",
    "        super(DKTWithFutureTaskID, self).__init__()\n",
    "        self.task_embedding = nn.Embedding(num_tasks, embed_size)        # Embedding layer for the task IDs\n",
    "        self.lstm = nn.LSTM(input_size=embed_size + 1, hidden_size=lstm_hidden_size, num_layers=1, batch_first=True)  # Task embedding + binary success/failure\n",
    "        self.fc = nn.Linear((lstm_hidden_size + embed_size), 1)\n",
    "        self.fc_all = nn.Linear(lstm_hidden_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, code_num, past_task_ids, past_successes, future_task_id):\n",
    "        past_task_embeddings = self.task_embedding(past_task_ids)  # Shape: (batch_size, num_past_tasks, embed_size)\n",
    "        past_input = torch.cat([past_task_embeddings, past_successes.unsqueeze(-1).float()], dim=-1)\n",
    "        snapshots_lstm = pack_padded_sequence(\n",
    "            past_input,\n",
    "            lengths=code_num.to('cpu'),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hn, cn) = self.lstm(snapshots_lstm)  \n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)  # (batch_size, max_seq_length, lstm_hidden_size)\n",
    "        future_task_embeddings = self.task_embedding(future_task_id) # Embed the future task ID \n",
    "        combined_input = torch.cat([hn[-1], future_task_embeddings], dim=-1) # Combine the LSTM output with the future task embedding\n",
    "        output = self.fc(combined_input)\n",
    "        all_question_preds = self.sig(self.fc_all(lstm_out))\n",
    "        return all_question_preds, self.sig(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function Option - caculate also all the past tasks loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunc = True\n",
    "class lossFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lossFunc, self).__init__()\n",
    "        self.crossEntropy = nn.BCELoss()\n",
    "\n",
    "    def forward(self, all_pred, target_prev, code_num, target_label):\n",
    "        loss = 0\n",
    "        pred, target_q = all_pred\n",
    "        pred = pred.to('cpu')\n",
    "        code_num = code_num.to('cpu')\n",
    "        target_q = target_q.to('cpu')\n",
    "        target_prev = target_prev.to('cpu')\n",
    "        target_label = target_label.to('cpu').unsqueeze(1)\n",
    "        for batch in range(pred.shape[0]):\n",
    "            s = code_num[batch]\n",
    "            p = torch.cat([pred.squeeze(-1)[batch, :s], target_q[batch]])\n",
    "            a = torch.cat([target_prev.squeeze(-1)[batch, :s], target_label[batch]])\n",
    "            loss += self.crossEntropy(p, a)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_1loss(batch, model, device, criterion):\n",
    "    dict_batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    model_params = {k: v for k, v in dict_batch.items() if k != 'label'}\n",
    "    logits = model(*model_params.values())\n",
    "    label = dict_batch['label'].float()\n",
    "    if not criterion:\n",
    "        return logits[1], label\n",
    "    if loss_func == False:\n",
    "        return criterion(logits[1], label.unsqueeze(1)) \n",
    "    return criterion(logits, batch['prev_label'], batch['code_num'], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DKTWithFutureTaskID(len(vocab))\n",
    "caculate_func = caculate_1loss\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=1e-4)\n",
    "\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split test, val, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing splitting\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = create_data_loader(df, StudentDataset, padding_size_code=padding_size_code, \n",
    "                                                                         text_tokenizer=vocab, batch_size=config.batch_size, create_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 39 75\n",
      "Label\n",
      "False    6372\n",
      "True     2018\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "False    921\n",
      "True     300\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "False    1826\n",
      "True      558\n",
      "Name: count, dtype: int64\n",
      "441 63 126\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader), len(valid_dataloader), len(test_dataloader), flush=True)\n",
    "print(train_dataloader.dataset.df['Label'].value_counts())\n",
    "print(valid_dataloader.dataset.df['Label'].value_counts())\n",
    "print(test_dataloader.dataset.df['Label'].value_counts())\n",
    "print(len(set(train_dataloader.dataset.df['student_id'])), len(set(valid_dataloader.dataset.df['student_id'])), len(set(test_dataloader.dataset.df['student_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/2025_23:27:54\n",
      "263 39\n",
      "Epoch: 0\n",
      "Batch 0 from 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3437120/3534076799.py:16: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  'label': torch.tensor(row['Label'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [1], LR: 0.000100, Loss: 0.7142, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 1\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [2], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 2\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [3], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 3\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [4], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 4\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [5], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 5\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [6], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 6\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [7], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 7\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [8], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 8\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [9], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 9\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [10], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "Epoch: 10\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [11], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 4\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 11\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [12], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 12\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [13], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "Epoch: 13\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [14], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 4\n",
      "Epoch: 14\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [15], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 3\n",
      "Epoch: 15\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [16], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 2\n",
      "Epoch: 16\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [17], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 1\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 17\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [18], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 18\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [19], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 19\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [20], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "Epoch: 20\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [21], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 4\n",
      "Epoch: 21\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [22], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 3\n",
      "success deep copy\n",
      "success save in a\n",
      "Epoch: 22\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [23], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 5\n",
      "Epoch: 23\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [24], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 4\n",
      "Epoch: 24\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [25], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 3\n",
      "Epoch: 25\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [26], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 2\n",
      "Epoch: 26\n",
      "Batch 0 from 263\n",
      "Batch 100 from 263\n",
      "Batch 200 from 263\n",
      "Test Batch 0 from 39\n",
      "Epoch [27], LR: 0.000100, Loss: 0.6932, Val Loss: 0.6932, patience: 1\n",
      "17/02/2025_23:28:38\n",
      "Loaded best model weights.\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model = training_loop(model=model, train_dataloader=train_dataloader, test_dataloader=valid_dataloader, \n",
    "                      optimizer=optimizer, criterion=criterion, device=device, name='a', caculate_func=caculate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(threshold, y_true, y_prob):\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.where(y_prob > threshold, 1, 0)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    best = \"best\"\n",
    "    if threshold == 0.5:\n",
    "        best = \"0.5\"\n",
    "    #  df = pd.concat([pd.DataFrame([[model_name, threshold, roc_auc, accuracy, precision, recall, f1]], columns=df.columns), df], ignore_index=True)\n",
    "    print({\"threshold\": threshold, \"roc_auc\": roc_auc, \"accuracy\": accuracy, f\"precision_{best}\": precision, f\"recall_{best}\": recall, f\"f1_{best}\": f1})\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch 0 from 39\n",
      "Test Batch 0 from 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3437120/3534076799.py:16: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  'label': torch.tensor(row['Label'])\n",
      "/tmp/ipykernel_3437120/3534076799.py:16: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  'label': torch.tensor(row['Label'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'threshold': np.float32(0.500011), 'roc_auc': np.float64(0.29765297750140346), 'accuracy': 0.7655201342281879, 'precision_best': np.float64(0.0), 'recall_best': np.float64(0.0), 'f1_best': np.float64(0.0)}\n",
      "[[1825    1]\n",
      " [ 558    0]]\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_probs = eval_loop(model, valid_dataloader, device, caculate_func=caculate_func)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "J = tpr - fpr\n",
    "best_index = J.argmax()\n",
    "\n",
    "y_labels, y_probs = eval_loop(model, test_dataloader, device, caculate_func=caculate_func)\n",
    "results(thresholds[best_index], y_labels, y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = create_data_loader_k_fold(df, StudentDataset, vocab, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 76\n",
      "504 126\n",
      "set()\n",
      "Label\n",
      "False    0.765811\n",
      "True     0.234189\n",
      "Name: proportion, dtype: float64\n",
      "Label\n",
      "False    0.738085\n",
      "True     0.261915\n",
      "Name: proportion, dtype: float64\n",
      "300 76\n",
      "504 126\n",
      "set()\n",
      "Label\n",
      "False    0.757667\n",
      "True     0.242333\n",
      "Name: proportion, dtype: float64\n",
      "Label\n",
      "False    0.770444\n",
      "True     0.229556\n",
      "Name: proportion, dtype: float64\n",
      "302 74\n",
      "504 126\n",
      "set()\n",
      "Label\n",
      "False    0.770388\n",
      "True     0.229612\n",
      "Name: proportion, dtype: float64\n",
      "Label\n",
      "False    0.71871\n",
      "True     0.28129\n",
      "Name: proportion, dtype: float64\n",
      "299 77\n",
      "504 126\n",
      "set()\n",
      "Label\n",
      "False    0.752907\n",
      "True     0.247093\n",
      "Name: proportion, dtype: float64\n",
      "Label\n",
      "False    0.788807\n",
      "True     0.211193\n",
      "Name: proportion, dtype: float64\n",
      "301 74\n",
      "504 126\n",
      "set()\n",
      "Label\n",
      "False    0.754337\n",
      "True     0.245663\n",
      "Name: proportion, dtype: float64\n",
      "Label\n",
      "False    0.784206\n",
      "True     0.215794\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def num_of(train_dataloader, test_dataloader):\n",
    "    print(len(train_dataloader), len(test_dataloader))\n",
    "    print(len(set(train_dataloader.dataset.df['student_id'])), len(set(test_dataloader.dataset.df['student_id'])))\n",
    "    print(set(train_dataloader.dataset.df['student_id']).intersection(set(test_dataloader.dataset.df['student_id'])))\n",
    "    print(train_dataloader.dataset.df.Label.value_counts(normalize=True))\n",
    "    print(test_dataloader.dataset.df.Label.value_counts(normalize=True))\n",
    "\n",
    "for train, test in data_loaders:\n",
    "    num_of(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results = {'ROC-AUC' : [], 'f1' : [], 'recall': [], \"precision\": []}\n",
    "\n",
    "for fold, (train_dataloader, test_dataloader) in enumerate(data_loaders):\n",
    "    print(f\"Fold {fold + 1}:\")    # Prepare data for current fold\n",
    "    m = DKTWithFutureTaskID(len(vocab))\n",
    "    loss_fn = None\n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=config.lr, weight_decay=1e-4)\n",
    "\n",
    "    m = m.to(device)\n",
    "    print(m)\n",
    "    # Training Loop\n",
    "    for epoch in range(config.epoch):\n",
    "        total_loss = train_loop(m, train_dataloader, device, optimizer, criterion, caculate_func)\n",
    "\n",
    "        # Optional: Print metrics every few epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Fold {fold + 1}, Epoch {epoch}: Loss = {total_loss / len(train_dataloader)}\")\n",
    "\n",
    "    y_labels, y_probs = eval_loop(m, test_dataloader, device, caculate_func=caculate_func)\n",
    "    y_prob = np.array(y_probs)\n",
    "    y_true = np.array(y_labels)\n",
    "    y_pred = np.where(y_prob > 0.25, 1, 0)\n",
    "\n",
    "    fold_results['ROC-AUC'].append(roc_auc_score(y_true, y_prob))\n",
    "    fold_results['precision'].append(precision_score(y_true, y_pred))\n",
    "    fold_results['recall'].append(recall_score(y_true, y_pred))\n",
    "    fold_results['f1'].append(f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
