{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from CodeDKT import *\n",
    "from torch.utils.data import DataLoader\n",
    "from readdata import data_reader, StudentDataset\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../../Data\")))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../..\")))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "from Data import *\n",
    "from choosedataset import *\n",
    "from helper import * \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.length = 100\n",
    "        self.lr = 0.0001\n",
    "        self.bs = 32\n",
    "        self.epochs = 15\n",
    "        self.hidden = 128\n",
    "        self.layers = 1\n",
    "        self.code_path_length = 8\n",
    "        self.code_path_width = 2\n",
    "        self.dataset = 0\n",
    "        self.padding_size_code = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_questions_dict(df):\n",
    "    all_future_q = set()\n",
    "    for i in df['new_task_id']:\n",
    "        all_future_q.add(i)\n",
    "\n",
    "    all_prev_q = set()\n",
    "    for i in df['prev_tasks_id']:\n",
    "        all_prev_q = all_prev_q.union(set(i))\n",
    "    all_problems = all_future_q.union(all_prev_q)\n",
    "    return {name: idx for idx, name in enumerate(all_problems)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [Codeworkout, Falcon][config.dataset]()\n",
    "df = data.df\n",
    "code_df = pd.read_csv(\"codedkt/labeled_paths_all.tsv\",sep=\"\\t\")\n",
    "df['prev_tasks'] = df['prev_tasks'].apply(lambda x: [i[-config.padding_size_code:] for i in x]) # n submissions padding_size_code snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df.rename(columns={'student_id': 'SubjectID'}, inplace=True)\n",
    "code_df.rename(columns={'clean_code': 'Code'}, inplace=True)\n",
    "question_dict = create_questions_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_1loss(batch, model, device, criterion, loss_fn=None):\n",
    "    dict_batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    model_params = {k: v for k, v in dict_batch.items() if k != 'label'}\n",
    "    logits = model(*model_params.values())\n",
    "    label = dict_batch['label'].float()\n",
    "    if not criterion:\n",
    "        return logits[1], label\n",
    "    loss = criterion(logits, batch['row'], label)\n",
    "    del dict_batch, model_params, logits, label\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "caculate_func = caculate_1loss\n",
    "criterion = lossFunc(len(question_dict), config.length, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, dataset, question_dict=None, batch_size=32, create_split=True):        \n",
    "    # Split the data to train and test by student ID\n",
    "    if not create_split:\n",
    "        print(\"Load exist spliting\")\n",
    "        train_ids, valid_ids, test_ids = load_ids(ids_filepath_prefix)\n",
    "    else:\n",
    "        student_id = df['student_id'].unique()\n",
    "        id_to_struggle = df.groupby('student_id')['Label'].first()\n",
    "        train_ids, test_ids = train_test_split(student_id, test_size=0.3, stratify=id_to_struggle[student_id])\n",
    "        valid_ids, test_ids = train_test_split(test_ids, test_size=0.2/0.3, stratify=id_to_struggle[test_ids])\n",
    "    handler = data_reader(df, code_df, question_dict, config.length, config.questions)\n",
    "    handler.get_data(train_ids, set(valid_ids).union(set(test_ids)))\n",
    "\n",
    "    train_df = df[df['student_id'].isin(train_ids)]\n",
    "    valid_df = df[df['student_id'].isin(valid_ids)]\n",
    "    test_df = df[df['student_id'].isin(test_ids)]\n",
    "    \n",
    "    # Tokenize\n",
    "    train_dataset = dataset(train_df, handler)\n",
    "    valid_dataset = dataset(valid_df, handler, \"test\")\n",
    "    test_dataset = dataset(test_df, handler, \"test\")\n",
    "\n",
    "    # Dataset\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)       \n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish test 189\n",
      "finish train 441\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = create_data_loader(df, StudentDataset, question_dict, batch_size=config.bs, create_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 36 76\n",
      "Label\n",
      "False    6409\n",
      "True     2019\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "False    879\n",
      "True     266\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "False    1831\n",
      "True      591\n",
      "Name: count, dtype: int64\n",
      "441 62 127\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader), len(valid_dataloader), len(test_dataloader), flush=True)\n",
    "print(train_dataloader.dataset.df['Label'].value_counts())\n",
    "print(valid_dataloader.dataset.df['Label'].value_counts())\n",
    "print(test_dataloader.dataset.df['Label'].value_counts())\n",
    "print(len(set(train_dataloader.dataset.df['student_id'])), len(set(valid_dataloader.dataset.df['student_id'])), len(set(test_dataloader.dataset.df['student_id'])))\n",
    "print(set(train_dataloader.dataset.df['student_id']).intersection(set(valid_dataloader.dataset.df['student_id'])))\n",
    "print(set(train_dataloader.dataset.df['student_id']).intersection(set(test_dataloader.dataset.df['student_id'])))\n",
    "print(set(valid_dataloader.dataset.df['student_id']).intersection(set(test_dataloader.dataset.df['student_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = train_dataloader.dataset.node_count\n",
    "path_count = train_dataloader.dataset.path_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = c2vRNNModel(config.questions * 2,\n",
    "                    config.hidden,\n",
    "                    config.layers,\n",
    "                    len(question_dict),\n",
    "                    node_count, path_count, device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"code-dkt\"\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=1e-4)\n",
    "model = training_loop(model=model, train_dataloader=train_dataloader, test_dataloader=valid_dataloader, optimizer=optimizer, criterion=criterion, device=device, name=name, caculate_func=caculate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch 0 from 80\n",
      "Test Batch 0 from 162\n",
      "Test Batch 100 from 162\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_probs = eval_loop(model, valid_dataloader, device, caculate_func=caculate_func)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "\n",
    "J = tpr - fpr\n",
    "best_index = J.argmax()\n",
    "best_threshold = thresholds[best_index]\n",
    "\n",
    "y_labels, y_probs = eval_loop(model, test_dataloader, device, caculate_func=caculate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(threshold, y_true, y_prob):\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.where(y_prob > threshold, 1, 0)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    best = \"best\"\n",
    "    if threshold == 0.5:\n",
    "        best = \"0.5\"\n",
    "    #  df = pd.concat([pd.DataFrame([[model_name, threshold, roc_auc, accuracy, precision, recall, f1]], columns=df.columns), df], ignore_index=True)\n",
    "    print({\"threshold\": threshold, \"roc_auc\": roc_auc, \"accuracy\": accuracy, f\"precision_{best}\": precision, f\"recall_{best}\": recall, f\"f1_{best}\": f1})\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'threshold': np.float32(0.58912784), 'roc_auc': np.float64(0.5504844865099237), 'accuracy': 0.5019305019305019, 'precision_best': np.float64(0.42108311613090066), 'recall_best': np.float64(0.7144963144963145), 'f1_best': np.float64(0.5298833819241983)}\n",
      "[[1146 1999]\n",
      " [ 581 1454]]\n"
     ]
    }
   ],
   "source": [
    "results(best_threshold, y_labels, y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader_k_fold(df, dataset, question_dict=None, batch_size=32, k=5):            # Setup k-fold\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    student_id = df['student_id'].unique()\n",
    "    id_to_struggle = df.groupby('student_id')['Label'].first()\n",
    "    data_loaders = []\n",
    "\n",
    "    # Perform k-fold split\n",
    "    for train_idx, test_idx in kf.split(student_id, id_to_struggle[student_id]):\n",
    "        train_students = student_id[train_idx]\n",
    "        test_students = student_id[test_idx]\n",
    "        handler = data_reader(df, code_df, question_dict, config.length, config.questions)\n",
    "        handler.get_data(train_students, test_students)\n",
    "        # Create train and test DataFrames\n",
    "        train_df = df[df['student_id'].isin(train_students)]\n",
    "        test_df = df[df['student_id'].isin(test_students)]\n",
    "\n",
    "        # Tokenize\n",
    "        train_dataset = dataset(train_df, handler)\n",
    "        test_dataset = dataset(test_df, handler, \"test\")\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Append to results\n",
    "        data_loaders.append((train_dataloader, test_dataloader))\n",
    "    return data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish test 126\n",
      "finish train 504\n",
      "finish test 126\n",
      "finish train 504\n",
      "finish test 126\n",
      "finish train 504\n",
      "finish test 126\n",
      "finish train 504\n",
      "finish test 126\n",
      "finish train 504\n"
     ]
    }
   ],
   "source": [
    "data_loaders = create_data_loader_k_fold(df, StudentDataset, question_dict, balanced_def=same_df, batch_size=config.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results = {'ROC-AUC' : [], 'f1' : [], 'recall': [], \"precision\": []}\n",
    "\n",
    "for fold, (train_dataloader, test_dataloader) in enumerate(data_loaders):\n",
    "    print(f\"Fold {fold + 1}:\")    # Prepare data for current fold\n",
    "    node_count = train_dataloader.dataset.node_count\n",
    "    path_count = train_dataloader.dataset.path_count\n",
    "\n",
    "    m = c2vRNNModel(config.questions * 2,\n",
    "                    config.hidden,\n",
    "                    config.layers,\n",
    "                    config.questions,\n",
    "                    node_count, path_count, device) \n",
    "    loss_fn = None\n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=config.lr, weight_decay=1e-4)\n",
    "\n",
    "    m = m.to(device)\n",
    "    print(m)\n",
    "    # Training Loop\n",
    "    for epoch in range(config.epochs):\n",
    "        total_loss = train_loop(m, train_dataloader, device, optimizer, criterion, caculate_func)\n",
    "\n",
    "        # Optional: Print metrics every few epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Fold {fold + 1}, Epoch {epoch}: Loss = {total_loss / len(train_dataloader)}\")\n",
    "\n",
    "    y_labels, y_probs = eval_loop(m, test_dataloader, device, caculate_func=caculate_func)\n",
    "    y_prob = np.array(y_probs)\n",
    "    y_true = np.array(y_labels)\n",
    "    y_pred = np.where(y_prob > 0.25, 1, 0)\n",
    "\n",
    "    fold_results['ROC-AUC'].append(roc_auc_score(y_true, y_prob))\n",
    "    fold_results['precision'].append(precision_score(y_true, y_pred))\n",
    "    fold_results['recall'].append(recall_score(y_true, y_pred))\n",
    "    fold_results['f1'].append(f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC-AUC': [np.float64(0.7038260755229249),\n",
       "  np.float64(0.713637798528403),\n",
       "  np.float64(0.6709280024788047),\n",
       "  np.float64(0.7061674180904653),\n",
       "  np.float64(0.7144690792863939)],\n",
       " 'f1': [np.float64(0.4151067323481117),\n",
       "  np.float64(0.37339635381498987),\n",
       "  np.float64(0.4390728476821192),\n",
       "  np.float64(0.3487352445193929),\n",
       "  np.float64(0.3549843695727683)],\n",
       " 'recall': [np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0)],\n",
       " 'precision': [np.float64(0.2619146290924161),\n",
       "  np.float64(0.22955583229555832),\n",
       "  np.float64(0.28128977513788717),\n",
       "  np.float64(0.21119281045751634),\n",
       "  np.float64(0.21579391891891891)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
